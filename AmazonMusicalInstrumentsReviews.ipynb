{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in c:\\users\\user\\desktop\\project\\env\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9 in c:\\users\\user\\desktop\\project\\env\\lib\\site-packages (from pyspark) (0.10.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Musical Instruments Reviews\n",
    "\n",
    "Webportals like Bhuvan get vast amount of feedback from the users. To go through all the feedback's can be a tedious job. You have to categorize opinions expressed in feedback forums. This can be utilized for feedback management system. We Classification of individual comments/reviews.and we also determining overall rating based on individual comments/reviews. So that company can get a complete idea on feedback's provided by customers and can take care on those particular fields. This makes more loyal Customers to the company, increase in business , fame ,brand value ,profits.\n",
    "\n",
    "## 1. Problem Definition\n",
    "\n",
    "In our case, the problem we will be exploring is regression.\n",
    "\n",
    "This is because we're going to be using a number of different features about reviews to predict them overall rating.\n",
    "\n",
    "## 2. Data \n",
    "\n",
    "The data we're using is from Kaggle : https://www.kaggle.com/eswarchandt/amazon-music-reviews\n",
    "\n",
    "## 3. Fetures \n",
    "\n",
    "This file has reviewer ID , User ID, Reviewer Name, Reviewer text, helpful, Summary(obtained from Reviewer text),Overall Rating on a scale 5, Review time\n",
    "Description of columns in the file:\n",
    "\n",
    "* reviewerID - ID of the reviewer, e.g. A2SUAM1J3GNN3B\n",
    "* asin - ID of the product, e.g. 0000013714\n",
    "* reviewerName - name of the reviewer\n",
    "* helpful - helpfulness rating of the review, e.g. 2/3\n",
    "* reviewText - text of the review\n",
    "* overall - rating of the product\n",
    "* summary - summary of the review\n",
    "* unixReviewTime - time of the review (unix time)\n",
    "* reviewTime - time of the review (raw)\n",
    "\n",
    "## Preparing the tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import avg, col, concat, desc, explode, lit, min, max, split, udf, from_unixtime\n",
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer, IDF, Normalizer, PCA, RegexTokenizer, StandardScaler, StopWordsRemover, VectorAssembler, StringIndexer, MinMaxScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a Spark Session to develop and train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spark session\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark Session\") \\\n",
    "    .getOrCreate()  # replace session if it has been created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load CSV file to Spark dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+--------------------+--------+--------------------+-------+--------------------+--------------------+-----------+\n",
      "|    reviewerID|      asin|        reviewerName| helpful|          reviewText|overall|             summary|      unixReviewTime| reviewTime|\n",
      "+--------------+----------+--------------------+--------+--------------------+-------+--------------------+--------------------+-----------+\n",
      "|A2IBPI20UZIR0U|1384719342|\"cassandra tu \"\"Yeah|    well|    that's just like|  u...\"|              [0, 0]|Not much to write...|        5.0|\n",
      "|A14VAT5EAX3D9S|1384719342|                Jake|[13, 14]|The product does ...|    5.0|                Jake|          1363392000|03 16, 2013|\n",
      "|A195EZSQDW3E21|1384719342|\"Rick Bennette \"\"...|  [1, 1]|The primary job o...|    5.0|It Does The Job Well|          1377648000|08 28, 2013|\n",
      "|A2C00NNG1ZQQG2|1384719342|\"RustyBill \"\"Sund...|  [0, 0]|Nice windscreen p...|    5.0|GOOD WINDSCREEN F...|          1392336000|02 14, 2014|\n",
      "| A94QU4C90B1AX|1384719342|       SEAN MASLANKA|  [0, 0]|This pop filter i...|    5.0|No more pops when...|          1392940800|02 21, 2014|\n",
      "|A2A039TZMZHH9Y|B00004Y2UT|\"Bill Lewey \"\"ble...|  [0, 0]|So good that I bo...|    5.0|      The Best Cable|          1356048000|12 21, 2012|\n",
      "|A1UPZM995ZAH90|B00004Y2UT|               Brian|  [0, 0]|I have used monst...|    5.0|Monster Standard ...|          1390089600|01 19, 2014|\n",
      "| AJNFQI3YR6XJ5|B00004Y2UT|\"Fender Guy \"\"Ric...|  [0, 0]|I now use this ca...|    3.0|Didn't fit my 199...|          1353024000|11 16, 2012|\n",
      "|A3M1PLEYNDEYO8|B00004Y2UT| \"G. Thomas \"\"Tom\"\"\"|  [0, 0]|Perfect for my Ep...|    5.0|         Great cable|          1215302400| 07 6, 2008|\n",
      "| AMNTZU1YQN1TH|B00004Y2UT|         Kurt Robair|  [0, 0]|Monster makes the...|    5.0|Best Instrument C...|          1389139200| 01 8, 2014|\n",
      "|A2NYK9KWFMJV4Y|B00004Y2UT|\"Mike Tarrani \"\"J...|  [6, 6]|Monster makes a w...|    5.0|One of the best i...|          1334793600|04 19, 2012|\n",
      "|A35QFQI0M46LWO|B00005ML71|       Christopher C|  [0, 0]|I got it to have ...|    4.0|It works great bu...|          1398124800|04 22, 2014|\n",
      "|A2NIT6BKW11XJQ|B00005ML71|                 Jai|  [0, 0]|If you are not us...|    3.0|HAS TO GET USE TO...|          1384646400|11 17, 2013|\n",
      "|A1C0O09LOLVI39|B00005ML71|             Michael|  [0, 0]|I love it, I used...|    5.0|             awesome|          1371340800|06 16, 2013|\n",
      "|A17SLR18TUMULM|B00005ML71|         Straydogger|  [0, 0]|I bought this to ...|    5.0|           It works!|          1356912000|12 31, 2012|\n",
      "|A2PD27UKAD3Q00|B00005ML71|\"Wilhelmina Zeitg...|  [0, 0]|I bought this to ...|    2.0|Definitely Not Fo...|          1376697600|08 17, 2013|\n",
      "| AKSFZ4G1AXYFC|B000068NSX|    \"C.E. \"\"Frank\"\"\"|  [0, 0]|This Fender cable...|    4.0|Durable Instrumen...|          1376352000|08 13, 2013|\n",
      "| A67OJZLHBBUQ9|B000068NSX|\"Charles F. Marks...|  [0, 0]|wanted it just on...|    5.0|fender 18 ft. Cal...|          1373328000| 07 9, 2013|\n",
      "|A2EZWZ8MBEDOLN|B000068NSX|              Charlo|  [3, 3]|I've been using t...|    5.0|So far so good.  ...|          1363564800|03 18, 2013|\n",
      "|A1CL807EOUPVP1|B000068NSX|             GunHawk|  [0, 0]|Fender cords look...|    5.0|Add California to...|          1375833600| 08 7, 2013|\n",
      "+--------------+----------+--------------------+--------+--------------------+-------+--------------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv('Musical_instruments_reviews.csv', header=True)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- reviewerID: string (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- reviewerName: string (nullable = true)\n",
      " |-- helpful: string (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- overall: string (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- unixReviewTime: string (nullable = true)\n",
      " |-- reviewTime: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Data\n",
    "\n",
    "To train our model we should have the data in the numerical format.\n",
    "\n",
    "### Clean Data\n",
    "\n",
    "We should avoid NULL in data. So, let's get all values where columns is not NULL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in input data = 10261\n",
      "Number of row after removing NULL = 10226\n"
     ]
    }
   ],
   "source": [
    "df = data\n",
    "\n",
    "for name in df.schema.names:\n",
    "    df = df.where(data[name].isNotNull())\n",
    "\n",
    "print(f'Number of rows in input data = {data.count()}\\nNumber of row after removing NULL = { df.count()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `unixReviewTime` to numeric format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewerID='A2IBPI20UZIR0U', asin='1384719342', reviewerName='\"cassandra tu \"\"Yeah', helpful=' well', reviewText=\" that's just like\", overall=' u...\"', summary='[0, 0]', unixReviewTime=\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", reviewTime='5.0', reviewTimeNumeric=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_int = udf(lambda x : int(x) if x.isdigit() else 0, IntegerType())\n",
    "\n",
    "df = df.withColumn(\"reviewTimeNumeric\", data_to_int(data['unixReviewTime']))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization splits strings into separate words. Spark has a Tokenizer class as well as RegexTokenizer, which allows for more control over the tokenization process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewerID='A2IBPI20UZIR0U', asin='1384719342', reviewerName='\"cassandra tu \"\"Yeah', helpful=' well', reviewText=\" that's just like\", overall=' u...\"', summary='[0, 0]', unixReviewTime=\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", reviewTime='5.0', reviewTimeNumeric=0, review_words=['that', 's', 'just', 'like'], summary_words=['0', '0'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for column \"reviewText\"\n",
    "regexTokenizer_reviewText = RegexTokenizer(inputCol=\"reviewText\", \n",
    "                                           outputCol=\"review_words\",\n",
    "                                           pattern=\"\\\\W\") #only words, without punctuation\n",
    "# for column \"summary\"\n",
    "regexTokenizer_summary = RegexTokenizer(inputCol=\"summary\", \n",
    "                                           outputCol=\"summary_words\",\n",
    "                                           pattern=\"\\\\W\") #only words, without punctuation\n",
    "\n",
    "df = regexTokenizer_reviewText.transform(df)\n",
    "df = regexTokenizer_summary.transform(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer\n",
    "\n",
    "Set how many words we would like to keep.\n",
    "\n",
    "`vocabSize` : we keep top 1000 the most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewerID='A2IBPI20UZIR0U', asin='1384719342', reviewerName='\"cassandra tu \"\"Yeah', helpful=' well', reviewText=\" that's just like\", overall=' u...\"', summary='[0, 0]', unixReviewTime=\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", reviewTime='5.0', reviewTimeNumeric=0, review_words=['that', 's', 'just', 'like'], summary_words=['0', '0'], TF_review=SparseVector(1000, {12: 1.0, 19: 1.0, 32: 1.0, 38: 1.0}), TF_summary=SparseVector(1000, {67: 2.0}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the term frequencies of the words\n",
    "cv_review = CountVectorizer(inputCol=\"review_words\", outputCol=\"TF_review\", vocabSize=1000)\n",
    "cv_summary = CountVectorizer(inputCol=\"summary_words\", outputCol=\"TF_summary\", vocabSize=1000)\n",
    "\n",
    "df = cv_review.fit(df).transform(df)\n",
    "df = cv_summary.fit(df).transform(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inter-Document Frequency\n",
    "\n",
    "Let's count TF-IDF - it shows to us importance of the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewerID='A2IBPI20UZIR0U', asin='1384719342', reviewerName='\"cassandra tu \"\"Yeah', helpful=' well', reviewText=\" that's just like\", overall=' u...\"', summary='[0, 0]', unixReviewTime=\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", reviewTime='5.0', reviewTimeNumeric=0, review_words=['that', 's', 'just', 'like'], summary_words=['0', '0'], TF_review=SparseVector(1000, {12: 1.0, 19: 1.0, 32: 1.0, 38: 1.0}), TF_summary=SparseVector(1000, {67: 2.0}), TFIDF_review=SparseVector(1000, {12: 0.8816, 19: 1.2298, 32: 1.3726, 38: 1.3972}), TFIDF_summary=SparseVector(1000, {67: 8.7305}))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf_review = IDF(inputCol='TF_review', outputCol='TFIDF_review')\n",
    "idf_summary = IDF(inputCol='TF_summary', outputCol='TFIDF_summary')\n",
    "\n",
    "df = idf_review.fit(df).transform(df)\n",
    "df = idf_summary.fit(df).transform(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StringIndexer\n",
    "\n",
    "We want to get labels to our `reviewerID`, `asin` and `overall` columns . For example, label = 1 - the most common word, label = 100 - the most uncommon word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewerID='A2IBPI20UZIR0U', asin='1384719342', reviewerName='\"cassandra tu \"\"Yeah', helpful=' well', reviewText=\" that's just like\", overall=' u...\"', summary='[0, 0]', unixReviewTime=\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", reviewTime='5.0', reviewTimeNumeric=0, review_words=['that', 's', 'just', 'like'], summary_words=['0', '0'], TF_review=SparseVector(1000, {12: 1.0, 19: 1.0, 32: 1.0, 38: 1.0}), TF_summary=SparseVector(1000, {67: 2.0}), TFIDF_review=SparseVector(1000, {12: 0.8816, 19: 1.2298, 32: 1.3726, 38: 1.3972}), TFIDF_summary=SparseVector(1000, {67: 8.7305}), reviewerID_indexed=66.0, asin_indexed=701.0, overall_indexed=6.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexer = StringIndexer(inputCols=['reviewerID', 'asin', 'overall'],\n",
    "                        outputCols=['reviewerID_indexed', 'asin_indexed', 'overall_indexed'])\n",
    "df = indexer.fit(df).transform(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for training\n",
    "\n",
    "Let's choose a LogisticRegression Model and train it. For this we should add a `label` column and a `features` column.\n",
    "\n",
    "* `label` - what we want to predict\n",
    "* `features` - we will use these values to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(reviewerID='A2IBPI20UZIR0U', asin='1384719342', reviewerName='\"cassandra tu \"\"Yeah', helpful=' well', reviewText=\" that's just like\", overall=' u...\"', summary='[0, 0]', unixReviewTime=\"Not much to write about here, but it does exactly what it's supposed to. filters out the pop sounds. now my recordings are much more crisp. it is one of the lowest prices pop filters on amazon so might as well buy it, they honestly work the same despite their pricing,\", reviewTime='5.0', reviewTimeNumeric=0, review_words=['that', 's', 'just', 'like'], summary_words=['0', '0'], TF_review=SparseVector(1000, {12: 1.0, 19: 1.0, 32: 1.0, 38: 1.0}), TF_summary=SparseVector(1000, {67: 2.0}), TFIDF_review=SparseVector(1000, {12: 0.8816, 19: 1.2298, 32: 1.3726, 38: 1.3972}), TFIDF_summary=SparseVector(1000, {67: 8.7305}), reviewerID_indexed=66.0, asin_indexed=701.0, overall_indexed=6.0, features=SparseVector(2003, {0: 66.0, 1: 701.0, 14: 0.8816, 21: 1.2298, 34: 1.3726, 40: 1.3972, 1069: 8.7305}))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assembler = (VectorAssembler()\n",
    "    .setInputCols([\"reviewerID_indexed\", \"asin_indexed\", \"TFIDF_review\", \"TFIDF_summary\", \"reviewTimeNumeric\"])\n",
    "    .setOutputCol(\"features\"))\n",
    "    \n",
    "df = assembler.transform(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split our data on train and test sets:\n",
    "\n",
    "* Train set = 80 % of all data\n",
    "* Test set = 20 % of all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data frame which has only feature and target (label)\n",
    "data_lr = df.select(col(\"overall_indexed\").alias(\"label\"), col(\"features\"))\n",
    "\n",
    "# split data\n",
    "train_df, test_df = data_lr.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and predicting\n",
    "\n",
    "Define a Logistic Regression Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = LogisticRegression(maxIter=5, regParam=0.0, elasticNetParam=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model\n",
    "LR = lr_model.fit(train_df)\n",
    "\n",
    "# predicting\n",
    "res_LR = LR.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of right predicted values equals 1279 from 1961\n",
      "Accuracy equals 0.7283726557773744\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of right predicted values equals {res_LR.filter(res_LR.label == res_LR.prediction).count()} from {res_LR.count()}')\n",
    "print(f'Accuracy equals {LR.summary.accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
